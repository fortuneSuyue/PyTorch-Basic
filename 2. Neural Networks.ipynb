{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Networks\n",
    "\n",
    "### Contents\n",
    "    1. Introduction\n",
    "    2. Dataset with MNIST\n",
    "    3. Define a Neural Network\n",
    "    4. Train the Model\n",
    "    5. Test the Model\n",
    "    6. Demonstrate the Model\n",
    "    7. Save the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "A neural network is a network composed of artificial neurons and nodes, modeled after the human brain architecture and activation process. It is mainly used to solve artificial intelligence problems. It is typically trained by a large amounts of data. \n",
    "<br> The below diagram describes a brief process of neural network. Inputs are multiplied by weights, and summed, and it is passed to activation function, which converts the output to a value in a specific range, -1 to 1 or 0 to 1. </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./Images/DNN.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are variations on the neural network that performs in a specific areas, such as feed-forward neural networks, convolutional neural networks, recurrent neural networks and such. \n",
    "<br> **Feed-forward neural network**, or deep neural networks, pass information in one direction and typically used in facial recognition and computer vision. </br>\n",
    "<br> **Convolutional neural network** is typically made up of convolutional layers, pooling layers, and fully-connected layers. It extracts features from a set of images, thus it is widely used in the field of image recognition but also sometimes used in natural language processing. </br>\n",
    "<br> **Recurrent neural network** save the output of processing nodes and feed it to the models back, in other words, it remember all processed information so as to reuse it in the future process. Natural language processing and time-series prediction tasks uses this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset with MNIST\n",
    "\n",
    "A neural network that will be introduced is for classifying MNIST(Modified National Institute of Standard and Technology database) images. It is a large database of handwritten digits and most widely used dataset for training and testing neural networks and for beginners. It contains 60,000 training images and 10,000 testing images and each image has a size of 28 * 28 (= 784) and is a binary image (black and white or 1-color channel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor() must be declared before Normalize()\n",
    "                           # It converts the range from [0, 255] to [0, 1]\n",
    "    transforms.Normalize(mean = (0.5, ), std = (0.5, ))\n",
    "    # mean: (m1, m2, ..., mn) and std: (s1, s2, ..., sn)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size is the number of training examples in one forward and backward pass.\n",
    "# As the computer is a binary machine, the magnitude of batch size is recommended to set powers of two (2^n). \n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# download and load the train data\n",
    "train_data = datasets.MNIST('./data/MNIST', \n",
    "                            download = True, \n",
    "                            train = True, \n",
    "                            transform = transform)\n",
    "train_loader = DataLoader(train_data, \n",
    "                          batch_size = batch_size, \n",
    "                          shuffle = True)\n",
    "\n",
    "# download and load the test data\n",
    "test_data = datasets.MNIST('./data/MNIST', \n",
    "                           download = True, # already downloaded so don't have to declare again\n",
    "                           train = False, \n",
    "                           transform = transform)\n",
    "\n",
    "test_loader = DataLoader(test_data, \n",
    "                         batch_size = batch_size, \n",
    "                         shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data has a 60,000 images and each image has a size of 28 * 28. Test data has a 10,000 images and each image has the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.size(), test_data.data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the data, the below code shows the random data within training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 8\n",
      "Size of Image: (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = torch.randint(0, len(train_data), (1, )).item()\n",
    "random_image = train_data[idx][0].squeeze().numpy()\n",
    "target_num = train_data[idx][1]\n",
    "print(\"Target: {}\".format(target_num))\n",
    "print(\"Size of Image: {}\".format(random_image.shape))\n",
    "plt.imshow(random_image, cmap = \"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting device on GPU if available, else CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define your own Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./Images/MNIST_Network.png\" align = \"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to build a neural network that classifies this dataset with PyTorch. Its input should be 784 (= 28 * 28) and output of 10. We can add more layers or deep learning techniques to increase the accuracy. \n",
    "<br> `nn.Sequential` is a 'sequential' container that modules such as Linear, Conv2D, and ReLU, are contained. It processes in the order the user put methods on it. </br>\n",
    "<br> `forward` function actually processes the `self.main`. Reading the below code will help understanding.\n",
    "<br>Image source: http://neuralnetworksanddeeplearning.com/chap1.html </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper-parameters\n",
    "\n",
    "input_size = 28 * 28 # (= 784)\n",
    "hidden_size = [512, 256, 64] # multi-layer perceptron\n",
    "num_classes = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size[0], hidden_size[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size[1], hidden_size[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size[2], num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the training process, cost function and optimizer should be declared for forward and backward pass. The reason for using CrossEntropyLoss instead of Softmax is that the former contains the latter. Adam optimizer is the best operating optimization so far. The learning rate is typically set to 0.01 or 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform AI-like tasks, in this case classification, the neural network must be trained using a large dataset - MNIST. All data of MNIST iterate per one epoch. First, declare `model.train()` to put the model in the training process. As PyTorch sets the gradients by default, declaring `optimizer.zero_grad()` is essential. Then it will loop through the mini batches of MNIST dataset and data will pass through the network and calculate the losses, gradients and run the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_batch = len(train_data) // batch_size\n",
    "    \n",
    "        for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "        \n",
    "            X = batch_images.view(-1, 28 * 28)\n",
    "            Y = batch_labels\n",
    "        \n",
    "            ### The below five lines should be memorized for further use.\n",
    "            # forward pass\n",
    "            pred = model(X)\n",
    "            # calculation of loss value\n",
    "            cost = criterion(pred, Y)\n",
    "            # Adding cost value to the cost_losses class for graph plot later.\n",
    "            # train_cost.append(cost.item())\n",
    "            \n",
    "            ## backward pass and optimization\n",
    "            # gradient initialization\n",
    "            optimizer.zero_grad()\n",
    "            # backward pass\n",
    "            cost.backward()\n",
    "            # parameter update\n",
    "            optimizer.step()\n",
    "        \n",
    "            # print statistics of training process\n",
    "            if (i+1) % 300 == 0:\n",
    "                print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f'\n",
    "                     %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n",
    "            #train_count.append((i * 64) + ((epoch - 1) * len(train_loader.dataset)))\n",
    "    \n",
    "    print(\"Learning Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/7], lter [300/937], Loss: 0.2844\n",
      "Epoch [1/7], lter [600/937], Loss: 0.1562\n",
      "Epoch [1/7], lter [900/937], Loss: 0.3172\n",
      "Epoch [2/7], lter [300/937], Loss: 0.1292\n",
      "Epoch [2/7], lter [600/937], Loss: 0.2046\n",
      "Epoch [2/7], lter [900/937], Loss: 0.0919\n",
      "Epoch [3/7], lter [300/937], Loss: 0.0655\n",
      "Epoch [3/7], lter [600/937], Loss: 0.0367\n",
      "Epoch [3/7], lter [900/937], Loss: 0.0228\n",
      "Epoch [4/7], lter [300/937], Loss: 0.0302\n",
      "Epoch [4/7], lter [600/937], Loss: 0.1029\n",
      "Epoch [4/7], lter [900/937], Loss: 0.0693\n",
      "Epoch [5/7], lter [300/937], Loss: 0.1166\n",
      "Epoch [5/7], lter [600/937], Loss: 0.0452\n",
      "Epoch [5/7], lter [900/937], Loss: 0.0972\n",
      "Epoch [6/7], lter [300/937], Loss: 0.0440\n",
      "Epoch [6/7], lter [600/937], Loss: 0.0823\n",
      "Epoch [6/7], lter [900/937], Loss: 0.0426\n",
      "Epoch [7/7], lter [300/937], Loss: 0.0069\n",
      "Epoch [7/7], lter [600/937], Loss: 0.3234\n",
      "Epoch [7/7], lter [900/937], Loss: 0.0096\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "train(model = model, num_epochs = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model, it is vital to evaluate the model with other sets of data, which are never used for  First, run `model.eval()` to set the model to evaluation mode. It turns off any drop-out or batch normalization layers in the model that should not be used during the test. `torch.no_grad()` disables autograd function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    \n",
    "    # declare that the model is about to evaluate\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_data:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += 1\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\"Accuracy of Test Images: %f %%\" % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Images: 97.070000 %\n"
     ]
    }
   ],
   "source": [
    "test(model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Demonstrate the Model\n",
    "It imports an image from test dataset and see if the learning is conducted properly or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = random.randint(0, len(test_data)-1)\n",
    "X_single_data = Variable(test_data.test_data[r:r + 1].view(-1,28*28).float())\n",
    "Y_single_data = Variable(test_data.test_labels[r:r + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [6]\n",
      "Prediction:  [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_prediction = model(X_single_data)\n",
    "plt.imshow(X_single_data.data.view(28, 28).numpy(), cmap='gray')\n",
    "\n",
    "print('Label: ', Y_single_data.data.view(1).numpy())\n",
    "print('Prediction: ', torch.max(single_prediction.data, 1)[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save the Model\n",
    "\n",
    "Saving the checkpoint of the model is always important as we might load it for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "save_path = './model/'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "torch.save(model.state_dict(), 'basic_nn.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
